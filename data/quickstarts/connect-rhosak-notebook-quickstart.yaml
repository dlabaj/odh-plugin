kind: ConsoleQuickStart
metadata:
  name: connect-rhosak-notebook
  annotations:
    opendatahub.io/categories: 'Data management,Deployment,Jupyter notebook,Model serving,Python'
spec:
  displayName: Connecting to Red Hat OpenShift Streams for Apache Kafka
  appName: rhosak
  durationMinutes: 10
  icon: 'images/red-hat.svg'
  description: Connect to Red Hat OpenShift Streams for Apache Kafka from a Jupyter notebook. 
  prerequisites: [You have completed the "Getting started with Red Hat OpenShift Streams for Apache Kafka" quick start]
  introduction: |-
    ### This quick start shows you how to connect to Streams for Apache Kafka from a Jupyter notebook.
    Welcome to the Red Hat OpenShift Streams for Apache Kafka quick start.  This quick start uses a Kafka instance, topic, and service account created from the [Streams for Apache Kafka dashboard](https://console.redhat.com/beta/application-services/streams/kafkas).  The creation of these resources is covered in the quick start [Getting started with Red Hat OpenShift Streams for Apache Kafka](https://console.redhat.com/beta/application-services/streams/resources?quickstart=getting-started).
  tasks:
    - title: Obtain Kafka credentials from the Streams for Apache Kafka dashboard
      description: |-
        Notebooks and applications need the connection information for your Kafka instance. Follow these steps to save the required information for later use.
        ### To obtain connection information to Streams for Apache Kafka:
        1. In the OpenShift Streams for Apache Kafka web console, go to **Streams for Apache Kafka > Kafka Instances**.  On the right side of your Kafka instance, click *Options* (&#8942;) &#x2192; **Connection**.
        1. On the **Connection** page, copy the **Bootstrap server** endpoint to a secure location. Your application requires this endpoint to connect to the Kafka instance.
        1. Click **Create service account** and copy the **Client ID** and **Client secret** to a secure location. Your application requires these credentials to authenticate the connection to the Kafka instance.
        1. After you save the generated credentials to a secure location, select the confirmation check box in the credentials window and close the window.
        1. Set access for your new service account.  To do this, on the **Kafka Instances** page of the web console, click the name of your Kafka instance. Select the **Access** tab, and click the **Manage access** button to **Assign permissions** for the appropriate level of access.

           *Example ACL permissions for a new service account*
            | Resource            | Permission |
            | -----------         | ----------- |
            | Topic Is *          | Allow All   |
            | Consumer group Is * | Allow All   |
            | Transactional ID *  | Allow All   |

        1. On the **Kafka Instances** page of the web console, click the name of your Kafka instance. Select the **Topics** tab, create a topic if you have not already done so, and copy your **Topic name** for future use.

        Youâ€™ll use the server, client, and topic information that you saved to configure your application to connect to your Kafka instances from your Jupyter Notebook.
      review:
        instructions: |-
          Did you save the bootstrap server endpoint to a secure location?

          Did you save the client credentials to a secure location?
        failedTaskHelp: This task is not verified yet. Try the task again.
      summary:
        success: You have obtained connection information for Kafka
        failed: Try the steps again.

    - title: Launch JupyterHub
      description: |-
        ### To find the JupyterHub Launch action:
        1. Click **Applications** &#x2192; **Enabled**.
        2. Find the JupyterHub card.
        3. Click **Launch** on the JupyterHub card to access the JupyterHub **Start a notebook server** page.

        A new browser tab will open displaying the **Start a notebook server** page.
      review:
        instructions: |-
          #### To verify you have launched JupyterHub:
          Is a new **JupyterHub** browser tab visible with the **Start a notebook server** page open?
        failedTaskHelp: This task is not verified yet. Try the task again.
      summary:
        success: You have launched JupyterHub.
        failed: Try the steps again.

    - title: Configure and start an environment with variables
      description: |-
        ### Configure and start an environment with variables for Kafka:
        1. Select a notebook image from the options provided.
        2. Select a container size based on your computation needs.
        3. Under **Environment variables** click **Add**
        4. For **variable name** enter `KAFKA_BOOTSTRAP_SERVER`
        5. For **variable value** enter the value for the Kafka **External server** that you obtained from the Streams for Apache Kafka connection information.
        `KAFKA_BOOTSTRAP_SERVER: <External server>`
        6. Add another variable by repeating steps 3-5.
        `KAFKA_TOPIC: <Topic name>`
        6. Add another variable by repeating steps 3-5.
        `KAFKA_USERNAME: <Client ID>`
        7. Add another variable by repeating steps 3-5.
        `KAFKA_PASSWORD: <Client secret>`
        8. Click the **Start** button.

        The **Start a notebook server** page will reload and indicate that the system is starting up.
      review:
        instructions: |-
          #### To verify that you have launched the Jupyter notebook:
          Do you see a message on the page that says **The server is starting up**?
        failedTaskHelp: This task is not verified yet. Try the task again.
      summary:
        success: Your server has started and the JupyterLab interface will load shortly. When the page displays a **Stop** option, proceed to the next step.
        failed: Try the steps again.

    - title: Download examples of kafka-python consumers and producers
      description: |-
        ### Download kafka-python example notebooks:
        You are ready to connect to Kafka. To get started you can download some examples of consumers and producers in notebooks using `git clone`.

        To clone the notebook-examples repository using the Git plugin:
        1. Click the **Git** dropdown menu.
        2. Click **Clone a Repository**.
        3. Enter `https://github.com/rh-aiservices-bu/notebook-examples.git`.
        4. Click **CLONE**.

        You should now have a **notebook-examples** directory.
      review:
        instructions: |-
          #### To verify the notebook-examples git repository cloned:
          Check the file explorer pane in JupyterLab. Do you see a folder named **notebook-examples**?
        failedTaskHelp: This task is not verified yet. Try the task again.
      summary:
        success: The notebook-examples repository was successfully cloned into your environment.
        failed:  Try the steps again.

    - title: Run examples of kafka-python consumers and producers
      description: |-
        ### Run the examples:
        1. In the file explorer, open the folder `notebook-examples/kafka-sasl-plain`.
        2. Open the notebook `1_kafka_producer.ipynb`.
        3. **Run all cells** in the notebook to send messages from the producer.
        4. Open the notebook `2_kafka_consumer_print.ipynb`.
        5. **Run all cells** in the notebook start a consumer receiving messages.
        6. Explore the other notebooks and write your own.
      review:
        instructions: |-
          #### To verify that messages are being sent/received:
          Check the output from the last cell in `2_kafka_consumer_print.ipynb` and make sure there are incoming messages printed there.
        failedTaskHelp: Check the values of your environment variables and try the task again.
      summary:
        success:  Your environment is now sending and receiving messages.
        failed:  Try the steps again.

  conclusion:  Congratulations! Your environment is now sending and receiving messages using Red Hat OpenShift Streams for Apache Kafka.
  nextQuickStart: []
